{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "from math import *\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 32: Likelihood Ratio Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time, we introduced Likelihood Ratio tests. Recall that the point of a likelihood ratio test is to compare the likelihood function under a hypothesized value of the parameter with the liklihood function at its maximum. Instead of looking at the ratio $\\Lambda$ itself, we often consider $-2\\log \\Lambda$ instead, since it has a handy distribution. \n",
    "\n",
    "### Example 1: Exponential Distribution\n",
    "\n",
    "Suppose $X_1,X_2,...,X_n$ is an iid sequence of random variables from the exponential distribution with unknown parameter $\\lambda$. Recall that the maximum likelihood estimate of $\\lambda$ is $1\\over\\bar{X}$. We collect a random sample of size 20 and want to test the hypothesis $H_0: \\lambda = 3$ vs $H_1: \\lambda \\neq 3$. Using the data in the python box below, conduct a likelihood ratio test on this hypothesis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data=np.array([0.18,0.277,0.105,0.126,0.225,0.026,0.123,0.423,0.006,0.281,0.050,0.692,0.105,0.275,0.346,0.079,0.045,0.222,0.063,0.281])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=20, minmax=(0.006, 0.692), mean=0.1965, variance=0.027176368421052633, skewness=1.3751532772375619, kurtosis=2.0594082496235426)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09445694279678146"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum Likelihood estimate of parameter\n",
    "xbar = np.mean(my_data)\n",
    "lam_ML = 1/xbar\n",
    "\n",
    "# Likelihood ratio test - uses f(x,lambda) for exponential distribution\n",
    "L_3 = (3**20)*exp(-3*20*xbar)\n",
    "L_ML = (lam_ML**20)*exp(-lam_ML*20*xbar)\n",
    "LAM = L_3/L_ML\n",
    "LAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.719222360188461"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stat = -2*np.log(LAM)\n",
    "test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02983"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_val = np.round(1-stats.chi2.cdf(test_stat,1),5)\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ratio test results in a value that is approximately zero, the estimate for $\\lambda$ under $H_o$ is unlikely to be correct. More specifically, the p-value for this data set is 0.02983. Thus, we reject $H_o$, as it has a 2.98% chance of being correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power\n",
    "\n",
    "Suppose that the true value of $\\lambda$ is 5. Let's determine the power of this test. Let $n=20$. Then determine the power if $n=50$. Remember, power is the probability of correctly rejecting the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, find what value of $-2 \\log \\Lambda$ would lead you to reject $H_0$. This is sometimes called the critical value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.841458820694124"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit = stats.chi2.ppf(0.95,1)\n",
    "crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stat(data,null,n):\n",
    "    lam_ML = 1/np.mean(data)\n",
    "    return -2*log((np.mean(data)**n)*(null**n)*e**(-null*sum(data)+n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, obtain the power. Obtain a sample of size 20 from the true population and obtain the value of $-2\\log \\Lambda$ for this sample. Repeat many times and determine how often you reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5949"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling, n = 20\n",
    "ts = []\n",
    "for i in np.arange(10**4):\n",
    "    x = stats.expon.rvs(scale=1/5,size=20) # random sample\n",
    "    ts = np.append(ts,test_stat(x,3,20))\n",
    "\n",
    "# Comparing test statistic to the critical value\n",
    "power20 = np.mean(ts>=crit) \n",
    "power20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for a sample size of 50. What do you expect to happen to power? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9497"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling, n = 50\n",
    "ts = []\n",
    "for i in np.arange(10**4):\n",
    "    x = stats.expon.rvs(scale=1/5,size=50) # random sample\n",
    "    ts = np.append(ts,test_stat(x,3,50))\n",
    "\n",
    "# Comparing test statistic to the critical value\n",
    "power50 = np.mean(ts>=crit) \n",
    "power50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a larger sample size, we expect to find a power closer to 1 since the probability of committing a Type I error should decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Different Test\n",
    "\n",
    "We've explored hypothesis tests in this class before. Taking advantage of our computing power, we don't have to rely on test statistics with asymptotic distributions. Let's conduct a more direct hypothesis test using simulation. Recall:\n",
    "\n",
    "$$\n",
    "H_0: \\lambda = 3\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_1: \\lambda \\neq 3\n",
    "$$\n",
    "\n",
    "Pick a different test statistic. Obtain an empirical distribution of that test statistic under $H_0$. Next, find the $p$-value by determining how often this test statistic is at or further away from the test statistic derived from the sample. Remember that this is a two-sided test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0382"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts2 = []\n",
    "for i in np.arange(10**4):\n",
    "    ts2 = np.append(ts2,np.mean(stats.expon.rvs(scale=1/3,size=20))) # new x-bar\n",
    "\n",
    "# Two-sided test\n",
    "2*np.mean(ts2<=xbar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the $p$-value compare to the LRT $p$-value? I wonder how the power of this test compares to our LRT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value associated with a scale of 1/3 for a two-sided test is lower than 0.05. This would lead us to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power\n",
    "\n",
    "Let's figure out the power of this test. First, determine for what values of the test statistic would lead us to reject $H_0$. These values can be referred to as your rejection region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20293176278018255, 0.4908637284482845]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit_low = percentile(2.5,ts2)\n",
    "crit_high = percentile(97.5,ts2)\n",
    "[crit_low,crit_high]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, determine the power of this test. Like in the LRT case, obtain a sample of size 20 and obtain the test statistic. Repeat many times and see how often your test statistic is in your rejection region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5535"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts2 = []\n",
    "for i in np.arange(10**4):\n",
    "    ts2 = np.append(ts2,np.mean(stats.expon.rvs(scale=1/5,size=20)))\n",
    "\n",
    "# Comparing test statistic 2 to the critical values\n",
    "power20 = np.mean(ts2<=crit_low) + np.mean(ts2>=crit_high)\n",
    "power20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for a sample size of 50. Note that you will have to obtain new critical values in order to do this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9456"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts2 = []\n",
    "for i in np.arange(10**4):\n",
    "    ts2 = np.append(ts2,np.mean(stats.expon.rvs(scale=1/3,size=50)))\n",
    "\n",
    "# Recalculate critical values for n = 50\n",
    "crit_low = percentile(2.5,ts2)\n",
    "crit_high = percentile(97.5,ts2)\n",
    "\n",
    "ts2 = []\n",
    "for i in np.arange(10**4):\n",
    "    ts2 = np.append(ts2,np.mean(stats.expon.rvs(scale=1/5,size=50)))\n",
    "    \n",
    "# Comparing test statistic 2 to the critical values\n",
    "power50 = np.mean(ts2<=crit_low) + np.mean(ts2>=crit_high)\n",
    "power50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
